{
 "cells": [
  {
   "source": [
    "## Train mode\n",
    "\n",
    "Get dataset from [https://www.kaggle.com/moltean/fruits](https://www.kaggle.com/moltean/fruits)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = os.path.join(data_dir, 'train')\n",
    "validation_data_dir = os.path.join(data_dir, 'val')\n",
    "print(train_data_dir, os.listdir(train_data_dir))\n",
    "print(validation_data_dir, os.listdir(validation_data_dir))\n",
    "len(os.listdir(train_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(train_data_dir + '/Banana/r_99_100.jpg')\n",
    "plt.imshow(img)\n",
    "print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "epochs = 5 #25\n",
    "batch_size = 16 #64\n",
    "numclasses = len(os.listdir(train_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    zoom_range = 0.2, # Randomly zoom image \n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = train_generator.n #3362\n",
    "nb_validation_samples = validation_generator.n #1127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50tl(input_shape, outclass, sigma):\n",
    "       \n",
    "    base_model = keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False)\n",
    "           \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    \n",
    "    prediction = Dense(outclass, activation=sigma)(x)\n",
    "    model = Model(inputs=base_model.input, outputs=prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50tl(input_shape, numclasses, 'softmax')\n",
    "lr = 1e-5\n",
    "decay = 1e-7 #0.0\n",
    "#optimizer = RMSprop(lr=lr, decay=decay)\n",
    "optimizer = SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"fruits-{epoch:02d}-{loss:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min', period=5)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        shuffle = True, verbose = 1,\n",
    "        validation_data = validation_generator,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "labels = ['Apple Red 1', 'Avocado', 'Banana', 'Cherry 1', 'Mango', 'Orange', 'Peach']\n",
    "#test_imgs = ['/Banana/r_45_100.jpg', '/Banana/105_100.jpg', '/Cherry 1/325_100.jpg', '/Peach/321_100.jpg']\n",
    "test_imgs = ['/Banana/0_100.jpg', '/Banana/122_100.jpg', '/Cherry/103_100.jpg', '/Peach/105_100.jpg']\n",
    "\n",
    "for test in test_imgs:\n",
    "    test_img = train_data_dir + test\n",
    "    img = image.load_img(test_img, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x /= 255.\n",
    "    classes = model.predict(x)\n",
    "    result = np.squeeze(classes)\n",
    "    result_indices = np.argmax(result)\n",
    "    \n",
    "    #img = Image.open(test_img)\n",
    "    #plt.axis('off')\n",
    "    #plt.title(\"{}, {}, {:.2f}%\".format(test, labels[result_indices], result[result_indices]*100))\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    print(\"{}, {}, {:.2f}%\".format(test, labels[result_indices], result[result_indices]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "training_acc = history.history['accuracy']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "fig=plt.figure(figsize=(12, 4))\n",
    "# Visualize loss history\n",
    "fig.add_subplot(121)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, training_acc, 'b-')\n",
    "plt.legend(['Training Loss', 'Training Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss/Acc')\n",
    "\n",
    "# Get training and test loss histories\n",
    "val_acc = history.history['val_accuracy']\n",
    "training_acc = history.history['accuracy']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(val_acc) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "fig.add_subplot(122)\n",
    "plt.plot(epoch_count, val_acc, 'r--')\n",
    "plt.plot(epoch_count, training_acc, 'b-')\n",
    "plt.legend(['Validation Accuracy', 'Training Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}